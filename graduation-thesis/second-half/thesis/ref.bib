@comment{
  file     ref.bib
  brief    bibliography references
  author   Kataoka Nagi al18036[at]shibaura-it.ac.jp
  date     2021-12-21 22:09:37
  Version: 1.0
  par      History
            add
  Copyright (c) 2021 Kataoka Nagi
}


@article{karimi_news_2018,
  title    = {News recommender systems – {Survey} and roads ahead},
  volume   = {54},
  issn     = {0306-4573},
  url      = {https://www.sciencedirect.com/science/article/pii/S030645731730153X},
  doi      = {10.1016/j.ipm.2018.04.008},
  abstract = {More and more people read the news online, e.g., by visiting the websites of their favorite newspapers or by navigating the sites of news aggregators. However, the abundance of news information that is published online every day through different channels can make it challenging for readers to locate the content they are interested in. The goal of News Recommender Systems (NRS) is to make reading suggestions to users in a personalized way. Due to their practical relevance, a variety of technical approaches to build such systems have been proposed over the last two decades. In this work, we review the state-of-the-art of designing and evaluating news recommender systems over the last ten years. One main goal of the work is to analyze which particular challenges of news recommendation (e.g., short item life times and recency aspects) have been well explored and which areas still require more work. Furthermore, in contrast to previous surveys, the paper specifically discusses methodological questions and today’s academic practice of evaluating and comparing different algorithmic news recommendation approaches based on accuracy measures.},
  language = {en},
  number   = {6},
  urldate  = {2021-06-25},
  journal  = {Information Processing \& Management},
  author   = {Karimi, Mozhgan and Jannach, Dietmar and Jugovac, Michael},
  month    = nov,
  year     = {2018},
  pages    = {1203--1227},
  file     = {Karimi et al_2018_News recommender systems – Survey and roads ahead.pdf:C\:\\Users\\calm3\\Dropbox\\zotero-sync\\Karimi et al_2018_News recommender systems – Survey and roads ahead.pdf:application/pdf}
}

@misc{pariser_beware_nodate,
  title    = {Beware online "filter bubbles"},
  url      = {https://www.ted.com/talks/eli_pariser_beware_online_filter_bubbles},
  abstract = {As web companies strive to tailor their services (including news and search results) to our personal tastes, there's a dangerous unintended consequence: We get trapped in a "filter bubble" and don't get exposed to information that could challenge or broaden our worldview. Eli Pariser argues powerfully that this will ultimately prove to be bad for us and bad for democracy.},
  language = {en},
  urldate  = {2022-01-06},
  author   = {Pariser, Eli}
}

@article{bruns_filter_2019,
  title    = {Filter bubble},
  volume   = {8},
  issn     = {2197-6775},
  url      = {https://policyreview.info/concepts/filter-bubble},
  abstract = {Concepts such as ‘filter bubble’ enjoy considerable popularity in scholarly as well as mainstream debates, but are rarely defined with any rigour. This has led to highly contradictory research findings. This article provides a critical review of the ‘filter bubble’ idea, and concludes that its persistence has served only to distract scholarly attention from far more critical areas of enquiry.},
  number   = {4},
  urldate  = {2021-05-29},
  journal  = {Internet Policy Review},
  author   = {Bruns, Axel},
  month    = nov,
  year     = {2019},
  file     = {Bruns_2019_Filter bubble.pdf:C\:\\Users\\calm3\\Dropbox\\zotero-sync\\Bruns_2019_Filter bubble.pdf:application/pdf}
}

@article{nguyen_echo_2020,
  title    = {{ECHO} {CHAMBERS} {AND} {EPISTEMIC} {BUBBLES}},
  volume   = {17},
  issn     = {1742-3600, 1750-0117},
  url      = {https://www.cambridge.org/core/journals/episteme/article/abs/echo-chambers-and-epistemic-bubbles/5D4AC3A808C538E17C50A7C09EC706F0},
  doi      = {10.1017/epi.2018.32},
  abstract = {Discussion of the phenomena of post-truth and fake news often implicates the closed epistemic networks of social media. The recent conversation has, however, blurred two distinct social epistemic phenomena. An epistemic bubble is a social epistemic structure in which other relevant voices have been left out, perhaps accidentally. An echo chamber is a social epistemic structure from which other relevant voices have been actively excluded and discredited. Members of epistemic bubbles lack exposure to relevant information and arguments. Members of echo chambers, on the other hand, have been brought to systematically distrust all outside sources. In epistemic bubbles, other voices are not heard; in echo chambers, other voices are actively undermined. It is crucial to keep these phenomena distinct. First, echo chambers can explain the post-truth phenomena in a way that epistemic bubbles cannot. Second, each type of structure requires a distinct intervention. Mere exposure to evidence can shatter an epistemic bubble, but may actually reinforce an echo chamber. Finally, echo chambers are much harder to escape. Once in their grip, an agent may act with epistemic virtue, but social context will pervert those actions. Escape from an echo chamber may require a radical rebooting of one's belief system.},
  language = {en},
  number   = {2},
  urldate  = {2022-01-06},
  journal  = {Episteme},
  author   = {Nguyen, C. Thi},
  month    = jun,
  year     = {2020},
  note     = {Publisher: Cambridge University Press},
  pages    = {141--161}
}

@misc{inc_echo_nodate,
  title   = {エコー‐チェンバー【echo chamber】},
  url     = {https://japanknowledge.com/lib/display/?lid=2001028535800},
  urldate = {2022-01-06},
  journal = {JapanKnowledge},
  author  = {Inc, NetAdvance}
}

@article{__2020-5,
  title    = {ウェブの功罪},
  volume   = {70},
  doi      = {10.18919/jkg.70.6_309},
  abstract = {多様な情報と人々をつなぐはずのソーシャルメディアが，社会的分断や情報のタコツボ化を助長しているという問題が顕在化している。特に，エコーチェンバーやフィルターバブルといった閉じた情報環境は，自分の好みに合致した情報のみが来やすく，自分とは異なる観点からの情報が来にくいため，フェイク（偽）ニュースやヘイト（憎悪）の温床となる危険性を孕んでいる。本稿では，計算社会科学の観点から，偽ニュースが拡散する仕組みについて解説し，ウェブの負の側面について論じる。また，今後のウェブの技術が克服すべき問題について議論する。},
  number   = {6},
  journal  = {情報の科学と技術},
  author   = {和俊, 笹原},
  year     = {2020},
  pages    = {309--314},
  file     = {和俊_2020_ウェブの功罪.pdf:C\:\\Users\\calm3\\Dropbox\\zotero-sync\\和俊_2020_ウェブの功罪.pdf:application/pdf}
}


@article{conover_partisan_2012,
  title     = {Partisan asymmetries in online political activity},
  volume    = {1},
  copyright = {2012 Conover et al.; licensee Springer.},
  issn      = {2193-1127},
  url       = {https://epjdatascience.springeropen.com/articles/10.1140/epjds6},
  doi       = {10.1140/epjds6},
  abstract  = {We examine partisan differences in the behavior, communication patterns and social interactions of more than 18,000 politically-active Twitter users to produce evidence that points to changing levels of partisan engagement with the American online political landscape. Analysis of a network defined by the communication activity of these users in proximity to the 2010 midterm congressional elections reveals a highly segregated, well clustered, partisan community structure. Using cluster membership as a high-fidelity (87\% accuracy) proxy for political affiliation, we characterize a wide range of differences in the behavior, communication and social connectivity of left- and right-leaning Twitter users. We find that in contrast to the online political dynamics of the 2008 campaign, right-leaning Twitter users exhibit greater levels of political activity, a more tightly interconnected social structure, and a communication network topology that facilitates the rapid and broad dissemination of political information.},
  language  = {en},
  number    = {1},
  urldate   = {2022-01-06},
  journal   = {EPJ Data Science},
  author    = {Conover, Michael D. and Gonçalves, Bruno and Flammini, Alessandro and Menczer, Filippo},
  month     = dec,
  year      = {2012},
  note      = {Number: 1 Publisher: SpringerOpen},
  pages     = {1--19},
  file      = {Conover et al_2012_Partisan asymmetries in online political activity.pdf:C\:\\Users\\calm3\\Dropbox\\zotero-sync\\Conover et al_2012_Partisan asymmetries in online political activity.pdf:application/pdf}
}

@inproceedings{nagulendra_understanding_2014,
  address    = {New York, NY, USA},
  series     = {{HT} '14},
  title      = {Understanding and controlling the filter bubble through interactive visualization: a user study},
  isbn       = {978-1-4503-2954-5},
  shorttitle = {Understanding and controlling the filter bubble through interactive visualization},
  url        = {https://doi.org/10.1145/2631775.2631811},
  doi        = {10.1145/2631775.2631811},
  abstract   = {The "filter bubble" is a term which refers to people getting encapsulated in streams of data such as news or social network updates that are personalized to their interests. While people need protection from information overload and maybe prefer to see content they feel familiar or agree with, there is the danger that important issues that should be of concern for everyone will get filtered away and people will lack exposure to different views, living in "echo-chambers", blissfully unaware of the reality. We have proposed a design of an interactive visualization, which provides the user of a social networking site with awareness of the personalization mechanism (the semantics and the source of the content that is filtered away), and with means to control the filtering mechanism. The visualization has been implemented in a peer-to-peer social network, called MADMICA, and we present here the results of a large scale lab study with 163 crowd-sourced participants. The results demonstrate that the visualization leads to increased users' awareness of the filter bubble, understandability of the filtering mechanism and to a feeling of control over their data stream.},
  urldate    = {2021-05-30},
  booktitle  = {Proceedings of the 25th {ACM} conference on {Hypertext} and social media},
  publisher  = {Association for Computing Machinery},
  author     = {Nagulendra, Sayooran and Vassileva, Julita},
  month      = sep,
  year       = {2014},
  pages      = {107--115},
  file       = {Full Text PDF:C\:\\Users\\calm3\\Zotero\\storage\\R6RPIXHN\\Nagulendra and Vassileva - 2014 - Understanding and controlling the filter bubble th.pdf:application/pdf}
}

@book{aurellen20,
  author    = {Aurélien Géron, 下田倫大, 長尾高弘},
  title     = {scikit-learn、Keras、TensorFlowによる実践機械学習 第2版},
  publisher = {株式会社オライリー・ジャパン},
  year      = {2020}
}

@article{bahdanau_neural_2016,
  title    = {Neural {Machine} {Translation} by {Jointly} {Learning} to {Align} and {Translate}},
  url      = {http://arxiv.org/abs/1409.0473},
  abstract = {Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.},
  urldate  = {2022-01-07},
  journal  = {arXiv:1409.0473 [cs, stat]},
  author   = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  month    = may,
  year     = {2016},
  note     = {arXiv: 1409.0473},
  file     = {Bahdanau et al_2016_Neural Machine Translation by Jointly Learning to Align and Translate.pdf:C\:\\Users\\calm3\\Dropbox\\zotero-sync\\Bahdanau et al_2016_Neural Machine Translation by Jointly Learning to Align and Translate.pdf:application/pdf}
}

@article{vaswani_attention_nodate,
  title    = {Attention is {All} you {Need}},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring signiﬁcantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.},
  language = {en},
  author   = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
  pages    = {11},
  file     = {Vaswani et al. - Attention is All you Need.pdf:C\:\\Users\\calm3\\Zotero\\storage\\I8GE8GRW\\Vaswani et al. - Attention is All you Need.pdf:application/pdf}
}

@article{devlin_bert_2019,
  title      = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
  shorttitle = {{BERT}},
  url        = {http://arxiv.org/abs/1810.04805},
  abstract   = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
  urldate    = {2021-07-23},
  journal    = {arXiv:1810.04805 [cs]},
  author     = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  month      = may,
  year       = {2019},
  note       = {arXiv: 1810.04805},
  file       = {Devlin et al_2019_BERT.pdf:C\:\\Users\\calm3\\Dropbox\\zotero-sync\\Devlin et al_2019_BERT.pdf:application/pdf}
}

@article{liu_roberta_2019,
  title      = {{RoBERTa}: {A} {Robustly} {Optimized} {BERT} {Pretraining} {Approach}},
  shorttitle = {{RoBERTa}},
  url        = {http://arxiv.org/abs/1907.11692},
  abstract   = {Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.},
  urldate    = {2021-07-25},
  journal    = {arXiv:1907.11692 [cs]},
  author     = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  month      = jul,
  year       = {2019},
  note       = {arXiv: 1907.11692},
  file       = {Liu et al_2019_RoBERTa.pdf:C\:\\Users\\calm3\\Dropbox\\zotero-sync\\Liu et al_2019_RoBERTa.pdf:application/pdf}
}

@article{chicco_advantages_2020,
  title    = {The advantages of the {Matthews} correlation coefficient ({MCC}) over {F1} score and accuracy in binary classification evaluation},
  volume   = {21},
  issn     = {1471-2164},
  url      = {https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-019-6413-7},
  doi      = {10.1186/s12864-019-6413-7},
  abstract = {Background: To evaluate binary classifications and their confusion matrices, scientific researchers can employ several statistical rates, accordingly to the goal of the experiment they are investigating. Despite being a crucial issue in machine learning, no widespread consensus has been reached on a unified elective chosen measure yet. Accuracy and F1 score computed on confusion matrices have been (and still are) among the most popular adopted metrics in binary classification tasks. However, these statistical measures can dangerously show overoptimistic inflated results, especially on imbalanced datasets.
              Results: The Matthews correlation coefficient (MCC), instead, is a more reliable statistical rate which produces a high score only if the prediction obtained good results in all of the four confusion matrix categories (true positives, false negatives, true negatives, and false positives), proportionally both to the size of positive elements and the size of negative elements in the dataset.
              Conclusions: In this article, we show how MCC produces a more informative and truthful score in evaluating binary classifications than accuracy and F1 score, by first explaining the mathematical properties, and then the asset of MCC in six synthetic use cases and in a real genomics scenario. We believe that the Matthews correlation coefficient should be preferred to accuracy and F1 score in evaluating binary classification tasks by all scientific communities.},
  language = {en},
  number   = {1},
  urldate  = {2022-01-17},
  journal  = {BMC Genomics},
  author   = {Chicco, Davide and Jurman, Giuseppe},
  month    = dec,
  year     = {2020},
  pages    = {6},
  file     = {Chicco and Jurman - 2020 - The advantages of the Matthews correlation coeffic.pdf:C\:\\Users\\calm3\\Zotero\\storage\\87UELQ7N\\Chicco and Jurman - 2020 - The advantages of the Matthews correlation coeffic.pdf:application/pdf}
}

@article{reimers_sentence-bert_2019,
  title      = {Sentence-{BERT}: {Sentence} {Embeddings} using {Siamese} {BERT}-{Networks}},
  shorttitle = {Sentence-{BERT}},
  url        = {https://arxiv.org/abs/1908.10084v1},
  abstract   = {BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations ({\textasciitilde}65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering. In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT. We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods.},
  language   = {en},
  urldate    = {2021-07-15},
  author     = {Reimers, Nils and Gurevych, Iryna},
  month      = aug,
  year       = {2019},
  file       = {Reimers_Gurevych_2019_Sentence-BERT.pdf:C\:\\Users\\calm3\\Dropbox\\zotero-sync\\Reimers_Gurevych_2019_Sentence-BERT2.pdf:application/pdf}
}


@article{murtagh_wards_2014,
  title      = {Ward’s {Hierarchical} {Agglomerative} {Clustering} {Method}: {Which} {Algorithms} {Implement} {Ward}’s {Criterion}?},
  volume     = {31},
  issn       = {1432-1343},
  shorttitle = {Ward’s {Hierarchical} {Agglomerative} {Clustering} {Method}},
  url        = {https://doi.org/10.1007/s00357-014-9161-z},
  doi        = {10.1007/s00357-014-9161-z},
  abstract   = {The Ward error sum of squares hierarchical clustering method has been very widely used since its first description by Ward in a 1963 publication. It has also been generalized in various ways. Two algorithms are found in the literature and software, both announcing that they implement the Ward clustering method. When applied to the same distance matrix, they produce different results. One algorithm preserves Ward’s criterion, the other does not. Our survey work and case studies will be useful for all those involved in developing software for data analysis using Ward’s hierarchical clustering method.},
  language   = {en},
  number     = {3},
  urldate    = {2022-01-24},
  journal    = {Journal of Classification},
  author     = {Murtagh, Fionn and Legendre, Pierre},
  month      = oct,
  year       = {2014},
  pages      = {274--295},
  file       = {Murtagh_Legendre_2014_Ward’s Hierarchical Agglomerative Clustering Method.pdf:C\:\\Users\\calm3\\Dropbox\\zotero-sync\\Murtagh_Legendre_2014_Ward’s Hierarchical Agglomerative Clustering Method.pdf:application/pdf}
}

@inproceedings{yang_scalable_2021,
  address   = {Montpellier, France},
  title     = {Scalable {Fact}-checking with {Human}-in-the-{Loop}},
  isbn      = {978-1-66541-717-4},
  url       = {https://ieeexplore.ieee.org/document/9648388/},
  doi       = {10.1109/WIFS53200.2021.9648388},
  abstract  = {Researchers have been investigating automated solutions for fact-checking in various fronts. However, current approaches often overlook the fact that information released every day is escalating, and a large amount of them overlap. Intending to accelerate fact-checking, we bridge this gap by proposing a new pipeline – grouping similar messages and summarizing them into aggregated claims. Speciﬁcally, we ﬁrst clean a set of social media posts (e.g., tweets) and build a graph of all posts based on their semantics; Then, we perform two clustering methods to group the messages for further claim summarization. We evaluate the summaries both quantitatively with ROUGE scores and qualitatively with human evaluation. We also generate a graph of summaries to verify that there is no signiﬁcant overlap among them. The results reduced 28,818 original messages to 700 summary claims, showing the potential to speed up the fact-checking process by organizing and selecting representative claims from massive disorganized and redundant messages.},
  language  = {en},
  urldate   = {2022-01-10},
  booktitle = {2021 {IEEE} {International} {Workshop} on {Information} {Forensics} and {Security} ({WIFS})},
  publisher = {IEEE},
  author    = {Yang, Jing and Vega-Oliveros, Didier and Seibt, Tais and Rocha, Anderson},
  month     = dec,
  year      = {2021},
  pages     = {1--6},
  file      = {Yang et al. - 2021 - Scalable Fact-checking with Human-in-the-Loop.pdf:C\:\\Users\\calm3\\Zotero\\storage\\5LSI387L\\Yang et al. - 2021 - Scalable Fact-checking with Human-in-the-Loop.pdf:application/pdf}
}

@inproceedings{rinott_show_2015,
  address   = {Lisbon, Portugal},
  title     = {Show {Me} {Your} {Evidence} - an {Automatic} {Method} for {Context} {Dependent} {Evidence} {Detection}},
  url       = {http://aclweb.org/anthology/D15-1050},
  doi       = {10.18653/v1/D15-1050},
  abstract  = {Engaging in a debate with oneself or others to take decisions is an integral part of our day-today life. A debate on a topic (say, use of performance enhancing drugs) typically proceeds by one party making an assertion/claim (say, PEDs are bad for health) and then providing an evidence to support the claim (say, a 2006 study shows that PEDs have psychiatric side effects). In this work, we propose the task of automatically detecting such evidences from unstructured text that support a given claim. This task has many practical applications in decision support and persuasion enhancement in a wide range of domains. We ﬁrst introduce an extensive benchmark data set tailored for this task, which allows training statistical models and assessing their performance. Then, we suggest a system architecture based on supervised learning to address the evidence detection task. Finally, promising experimental results are reported.},
  language  = {en},
  urldate   = {2021-12-10},
  booktitle = {Proceedings of the 2015 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
  publisher = {Association for Computational Linguistics},
  author    = {Rinott, Ruty and Dankin, Lena and Alzate Perez, Carlos and Khapra, Mitesh M. and Aharoni, Ehud and Slonim, Noam},
  year      = {2015},
  pages     = {440--450},
  file      = {Evidence2015.pdf:C\:\\Users\\calm3\\Zotero\\storage\\QBED8NEW\\Evidence2015.pdf:application/pdf}
}

@article{ghasiya_investigating_2021,
  title      = {Investigating {COVID}-19 {News} {Across} {Four} {Nations}: {A} {Topic} {Modeling} and {Sentiment} {Analysis} {Approach}},
  volume     = {9},
  issn       = {2169-3536},
  shorttitle = {Investigating {COVID}-19 {News} {Across} {Four} {Nations}},
  doi        = {10.1109/ACCESS.2021.3062875},
  abstract   = {Newspapers are very important for a society as they inform citizens about the events around them and how they can impact their life. Their importance becomes more crucial and indispensable in the times of health crisis such as the current COVID-19 pandemic. Since the starting of this pandemic newspapers are providing rich information to the public about various issues such as the discovery of a new strain of coronavirus, lockdown and other restrictions, government policies, and information related to the vaccine development for the same. In this scenario, analysis of emergent and widely reported topics/themes/issues and associated sentiments from various countries can help us better understand the COVID-19 pandemic. In our research, the database of more than 100,000 COVID-19 news headlines and articles were analyzed using top2vec (for topic modeling) and RoBERTa (for sentiment classification and analysis). Our topic modeling results highlighted that education, economy, US, and sports are some of the most common and widely reported themes across UK, India, Japan, South Korea. Further, our sentiment classification model achieved 90\% validation accuracy and the analysis showed that the worst affected country, i.e. the UK (in our dataset) also has the highest percentage of negative sentiment.},
  journal    = {IEEE Access},
  author     = {Ghasiya, Piyush and Okamura, Koji},
  year       = {2021},
  note       = {Conference Name: IEEE Access},
  pages      = {36645--36656},
  file       = {Ghasiya_Okamura_2021_Investigating COVID-19 News Across Four Nations.pdf:C\:\\Users\\calm3\\Dropbox\\zotero-sync\\Ghasiya_Okamura_2021_Investigating COVID-19 News Across Four Nations.pdf:application/pdf}
}

@article{kreuzthaler_detection_2015,
  title    = {Detection of sentence boundaries and abbreviations in clinical narratives},
  volume   = {15},
  issn     = {1472-6947},
  url      = {https://doi.org/10.1186/1472-6947-15-S2-S4},
  doi      = {10.1186/1472-6947-15-S2-S4},
  abstract = {In Western languages the period character is highly ambiguous, due to its double role as sentence delimiter and abbreviation marker. This is particularly relevant in clinical free-texts characterized by numerous anomalies in spelling, punctuation, vocabulary and with a high frequency of short forms.},
  number   = {2},
  urldate  = {2022-01-25},
  journal  = {BMC Medical Informatics and Decision Making},
  author   = {Kreuzthaler, Markus and Schulz, Stefan},
  month    = jun,
  year     = {2015},
  pages    = {S4},
  file     = {Kreuzthaler_Schulz_2015_Detection of sentence boundaries and abbreviations in clinical narratives.pdf:C\:\\Users\\calm3\\Dropbox\\zotero-sync\\Kreuzthaler_Schulz_2015_Detection of sentence boundaries and abbreviations in clinical narratives.pdf:application/pdf}
}

%% professor's template
@comment{
  @book{Kinoshita81,
    author    = "木下 是雄",
    title     = "理科系の作文技術",
    publisher = "中央公論社",
    year      = "1981",
    series    = "中公新書",
    number    = "624",
    URL       = "https://ci.nii.ac.jp/ncid/BN00624169"
  }


  @book{Yuki13,
    author    = "結城 浩",
    title     = "数学文章作法 基礎編",
    publisher = "ちくま学芸文庫",
    year      = "2013"
  }



  @article{Ijiri18,
    title = {Digitization of natural objects with micro CT and photographs},
    author = {Takashi Ijiri and Hideki Todo and Akira Hirabayashi and Kenji Kohiyama and Yoshinori Dobashi},
    journal = {PLoS ONE},
    month = {4},
    number = {4},
    volume = {13},
    year = {2018}
  }


  @misc{TexLive,
          author  = {TeX Users Group},
          title   = {TeX Live. \url{https://www.tug.org/texlive/}},
          note    = {(2021年5月28日参照)}
  }
}
