
@article{karimi_news_2018,
  title        = {News recommender systems – Survey and roads ahead},
  volume       = {54},
  issn         = {0306-4573},
  url          = {https://www.sciencedirect.com/science/article/pii/S030645731730153X},
  doi          = {10.1016/j.ipm.2018.04.008},
  abstract     = {More and more people read the news online, e.g., by visiting the websites of their favorite newspapers or by navigating the sites of news aggregators. However, the abundance of news information that is published online every day through different channels can make it challenging for readers to locate the content they are interested in. The goal of News Recommender Systems ({NRS}) is to make reading suggestions to users in a personalized way. Due to their practical relevance, a variety of technical approaches to build such systems have been proposed over the last two decades. In this work, we review the state-of-the-art of designing and evaluating news recommender systems over the last ten years. One main goal of the work is to analyze which particular challenges of news recommendation (e.g., short item life times and recency aspects) have been well explored and which areas still require more work. Furthermore, in contrast to previous surveys, the paper specifically discusses methodological questions and today’s academic practice of evaluating and comparing different algorithmic news recommendation approaches based on accuracy measures.},
  pages        = {1203--1227},
  number       = {6},
  journaltitle = {Information Processing \& Management},
  shortjournal = {Information Processing \& Management},
  author       = {Karimi, Mozhgan and Jannach, Dietmar and Jugovac, Michael},
  urldate      = {2021-06-25},
  date         = {2018-11},
  langid       = {english},
  file         = {Karimi et al_2018_News recommender systems – Survey and roads ahead.pdf:C\:\\Users\\calm3\\Dropbox\\zotero-sync\\Karimi et al_2018_News recommender systems – Survey and roads ahead.pdf:application/pdf}
}

@inproceedings{yang_scalable_2021,
  address   = {Montpellier, France},
  title     = {Scalable {Fact}-checking with {Human}-in-the-{Loop}},
  isbn      = {978-1-66541-717-4},
  url       = {https://ieeexplore.ieee.org/document/9648388/},
  doi       = {10.1109/WIFS53200.2021.9648388},
  abstract  = {Researchers have been investigating automated solutions for fact-checking in various fronts. However, current approaches often overlook the fact that information released every day is escalating, and a large amount of them overlap. Intending to accelerate fact-checking, we bridge this gap by proposing a new pipeline – grouping similar messages and summarizing them into aggregated claims. Speciﬁcally, we ﬁrst clean a set of social media posts (e.g., tweets) and build a graph of all posts based on their semantics; Then, we perform two clustering methods to group the messages for further claim summarization. We evaluate the summaries both quantitatively with ROUGE scores and qualitatively with human evaluation. We also generate a graph of summaries to verify that there is no signiﬁcant overlap among them. The results reduced 28,818 original messages to 700 summary claims, showing the potential to speed up the fact-checking process by organizing and selecting representative claims from massive disorganized and redundant messages.},
  language  = {en},
  urldate   = {2022-01-10},
  booktitle = {2021 {IEEE} {International} {Workshop} on {Information} {Forensics} and {Security} ({WIFS})},
  publisher = {IEEE},
  author    = {Yang, Jing and Vega-Oliveros, Didier and Seibt, Tais and Rocha, Anderson},
  month     = dec,
  year      = {2021},
  pages     = {1--6},
  file      = {Yang et al. - 2021 - Scalable Fact-checking with Human-in-the-Loop.pdf:C\:\\Users\\calm3\\Zotero\\storage\\5LSI387L\\Yang et al. - 2021 - Scalable Fact-checking with Human-in-the-Loop.pdf:application/pdf}
}

@article{ghasiya_investigating_2021,
  title      = {Investigating {COVID}-19 {News} {Across} {Four} {Nations}: {A} {Topic} {Modeling} and {Sentiment} {Analysis} {Approach}},
  volume     = {9},
  issn       = {2169-3536},
  shorttitle = {Investigating {COVID}-19 {News} {Across} {Four} {Nations}},
  doi        = {10.1109/ACCESS.2021.3062875},
  abstract   = {Newspapers are very important for a society as they inform citizens about the events around them and how they can impact their life. Their importance becomes more crucial and indispensable in the times of health crisis such as the current COVID-19 pandemic. Since the starting of this pandemic newspapers are providing rich information to the public about various issues such as the discovery of a new strain of coronavirus, lockdown and other restrictions, government policies, and information related to the vaccine development for the same. In this scenario, analysis of emergent and widely reported topics/themes/issues and associated sentiments from various countries can help us better understand the COVID-19 pandemic. In our research, the database of more than 100,000 COVID-19 news headlines and articles were analyzed using top2vec (for topic modeling) and RoBERTa (for sentiment classification and analysis). Our topic modeling results highlighted that education, economy, US, and sports are some of the most common and widely reported themes across UK, India, Japan, South Korea. Further, our sentiment classification model achieved 90\% validation accuracy and the analysis showed that the worst affected country, i.e. the UK (in our dataset) also has the highest percentage of negative sentiment.},
  journal    = {IEEE Access},
  author     = {Ghasiya, Piyush and Okamura, Koji},
  year       = {2021},
  note       = {Conference Name: IEEE Access},
  pages      = {36645--36656},
  file       = {Ghasiya_Okamura_2021_Investigating COVID-19 News Across Four Nations.pdf:C\:\\Users\\calm3\\Dropbox\\zotero-sync\\Ghasiya_Okamura_2021_Investigating COVID-19 News Across Four Nations.pdf:application/pdf}
}

@article{liu_roberta_2019,
  title      = {{RoBERTa}: {A} {Robustly} {Optimized} {BERT} {Pretraining} {Approach}},
  shorttitle = {{RoBERTa}},
  url        = {http://arxiv.org/abs/1907.11692},
  abstract   = {Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.},
  urldate    = {2021-07-25},
  journal    = {arXiv:1907.11692 [cs]},
  author     = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  month      = jul,
  year       = {2019},
  note       = {arXiv: 1907.11692},
  file       = {Liu et al_2019_RoBERTa.pdf:C\:\\Users\\calm3\\Dropbox\\zotero-sync\\Liu et al_2019_RoBERTa.pdf:application/pdf}
}

@inproceedings{rinott_show_2015,
  address   = {Lisbon, Portugal},
  title     = {Show {Me} {Your} {Evidence} - an {Automatic} {Method} for {Context} {Dependent} {Evidence} {Detection}},
  url       = {http://aclweb.org/anthology/D15-1050},
  doi       = {10.18653/v1/D15-1050},
  abstract  = {Engaging in a debate with oneself or others to take decisions is an integral part of our day-today life. A debate on a topic (say, use of performance enhancing drugs) typically proceeds by one party making an assertion/claim (say, PEDs are bad for health) and then providing an evidence to support the claim (say, a 2006 study shows that PEDs have psychiatric side effects). In this work, we propose the task of automatically detecting such evidences from unstructured text that support a given claim. This task has many practical applications in decision support and persuasion enhancement in a wide range of domains. We ﬁrst introduce an extensive benchmark data set tailored for this task, which allows training statistical models and assessing their performance. Then, we suggest a system architecture based on supervised learning to address the evidence detection task. Finally, promising experimental results are reported.},
  language  = {en},
  urldate   = {2021-12-10},
  booktitle = {Proceedings of the 2015 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
  publisher = {Association for Computational Linguistics},
  author    = {Rinott, Ruty and Dankin, Lena and Alzate Perez, Carlos and Khapra, Mitesh M. and Aharoni, Ehud and Slonim, Noam},
  year      = {2015},
  pages     = {440--450},
  file      = {Evidence2015.pdf:C\:\\Users\\calm3\\Zotero\\storage\\QBED8NEW\\Evidence2015.pdf:application/pdf}
}

@article{qi_stanza_2020,
  title      = {Stanza: {A} {Python} {Natural} {Language} {Processing} {Toolkit} for {Many} {Human} {Languages}},
  shorttitle = {Stanza},
  url        = {http://arxiv.org/abs/2003.07082},
  abstract   = {We introduce Sta n z a , an open-source Python natural language processing toolkit supporting 66 human languages. Compared to existing widely used toolkits, Sta n z a features a language-agnostic fully neural pipeline for text analysis, including tokenization, multiword token expansion, lemmatization, part-ofspeech and morphological feature tagging, dependency parsing, and named entity recognition. We have trained Sta n z a on a total of 112 datasets, including the Universal Dependencies treebanks and other multilingual corpora, and show that the same neural architecture generalizes well and achieves competitive performance on all languages tested. Additionally, Sta n z a includes a native Python interface to the widely used Java Stanford CoreNLP software, which further extends its functionality to cover other tasks such as coreference resolution and relation extraction. Source code, documentation, and pretrained models for 66 languages are available at https:// stanfordnlp.github.io/stanza/.},
  language   = {en},
  urldate    = {2021-11-09},
  journal    = {arXiv:2003.07082 [cs]},
  author     = {Qi, Peng and Zhang, Yuhao and Zhang, Yuhui and Bolton, Jason and Manning, Christopher D.},
  month      = apr,
  year       = {2020},
  note       = {arXiv: 2003.07082},
  file       = {Qi et al. - 2020 - Stanza A Python Natural Language Processing Toolk.pdf:C\:\\Users\\calm3\\Zotero\\storage\\EEYCCDGN\\Qi et al. - 2020 - Stanza A Python Natural Language Processing Toolk.pdf:application/pdf}
}

@misc{2021_world_press_freedom_index,
  title      = {2021 {World} {Press} {Freedom} {Index}: {Journalism}, the vaccine against disinformation, blocked in more than 130 countries},
  shorttitle = {2021 {World} {Press} {Freedom} {Index}},
  author     = {RSF},
  url        = {https://rsf.org/en/2021-world-press-freedom-index-journalism-vaccine-against-disinformation-blocked-more-130-countries},
  abstract   = {Читать на русском / Read in Russian This year’s Index, which evaluates the press freedom situation in 180 countries and territories annually, shows that journalism, journalism, which is arguably the best vaccine against the virus of disinformation, is totally blocked or seriously impeded in 73 countries and constrained in 59 others, which together represent 73\% of the countries evaluated. These countries are classified as having “very bad,” “bad” or “problematic” environments for press freedom, and are identified accordingly in black, red or orange on the World Press Freedom map.},
  language   = {en},
  urldate    = {2021-07-04},
  journal    = {RSF},
  note       = {\url{https://rsf.org/en/2021-world-press-freedom-index-journalism-vaccine-against-disinformation-blocked-more-130-countries} (2021年7月19日参照)}
}

@comment{
%% 	month = apr,
%% 	year = {2021},
}

@inproceedings{tian_labeled_2018,
  title     = {Labeled {Bilingual} {Topic} {Model} for {Cross}-{Lingual} {Text} {Classification} and {Label} {Recommendation}},
  doi       = {10.1109/ICISCE.2018.00067},
  abstract  = {Aiming at the increasingly rich multi language information resources and multi-label data in news reports and scientific literatures, in order to mining the relevance between languages and the correlation between data, this paper proposed labeled bilingual topic model, applied on cross-lingual text classification and label recommendation. First of all, it could assume that the keywords in the scientific literature are relevant to the abstract in same article, then extracted the keywords and regarded it as labels, and aligned the labels with topics in topic model, instantiated the “latent” topic. Secondly, trained the abstracts in article through the topic model proposed by this paper. Finally, classified the new documents by cross-lingual text classifier, also recommended the labels. The experiment result show that Micro-F1 measure reaches 94.81\% in cross-lingual text classification task, and the recommended labels also reflects the sematic relevance with documents.},
  booktitle = {2018 5th {International} {Conference} on {Information} {Science} and {Control} {Engineering} ({ICISCE})},
  author    = {Tian, Ming-Jie and Huang, Zheng-Hao and Cui, Rong-Yi},
  month     = jul,
  year      = {2018},
  keywords  = {topic model, cross-lingual text classification, Data models, Dictionaries, label, label recommendation, latent topic, Probabilistic logic, Probability, Semantics, Task analysis, Text categorization},
  pages     = {285--289},
  file      = {Tian et al. - 2018 - Labeled Bilingual Topic Model for Cross-Lingual Te.pdf:C\:\\Users\\calm3\\Zotero\\storage\\J5YY896G\\Tian et al. - 2018 - Labeled Bilingual Topic Model for Cross-Lingual Te.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\calm3\\Zotero\\storage\\RCWFIPXW\\8612565.html:text/html}
}

@article{reimers_sentence-bert_2019,
  title      = {Sentence-{BERT}: {Sentence} {Embeddings} using {Siamese} {BERT}-{Networks}},
  shorttitle = {Sentence-{BERT}},
  url        = {https://arxiv.org/abs/1908.10084v1},
  abstract   = {BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations ({\textasciitilde}65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering. In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT. We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods.},
  language   = {en},
  urldate    = {2021-07-15},
  author     = {Reimers, Nils and Gurevych, Iryna},
  file       = {Reimers_Gurevych_2019_Sentence-BERT.pdf:C\:\\Users\\calm3\\Dropbox\\zotero-sync\\Reimers_Gurevych_2019_Sentence-BERT.pdf:application/pdf},
  note       = {\url{https://arxiv.org/abs/1908.10084v1} (2021年7月19日参照)}
}
@comment{,
  month = aug,
  year  = {2019}
}

@comment{
}

@misc{debater_datasets,
  type      = {{CT002}},
  author    = {IBM Corporation},
  title     = {Project Debater Datasets},
  copyright = {© Copyright IBM Corp. 2011},
  url       = {http://www.research.ibm.com/labs/haifa/},
  abstract  = {IBM Research - Haifa is the largest lab of IBM Research Division outside of the United States. Founded as a small scientific center in 1972, it grew into a major lab that leads the development of innovative technological products and solutions for the IBM corporation.},
  language  = {en-US},
  urldate   = {2021-07-19},
  note      = {\url{https://www.research.ibm.com/haifa/dept/vst/debating_data.shtml} (2021年7月19日参照)}
}
@comment{,
  title = {{IBM} {Research}},
  note  = {Publisher: IBM Corporation},
  month = feb,
  year  = {2017}
}

@article{blei_latent_nodate,
  title    = {Latent {Dirichlet} {Allocation}},
  abstract = {We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a ﬁnite mixture over an underlying set of topics. Each topic is, in turn, modeled as an inﬁnite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efﬁcient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classiﬁcation, and collaborative ﬁltering, comparing to a mixture of unigrams model and the probabilistic LSI model.},
  language = {en},
  author   = {Blei, David M},
  pages    = {30},
  file     = {Blei - Latent Dirichlet Allocation.pdf:C\:\\Users\\calm3\\Zotero\\storage\\P8CUU5P6\\Blei - Latent Dirichlet Allocation.pdf:application/pdf}
}
