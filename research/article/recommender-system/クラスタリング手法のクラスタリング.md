<!-- tex script for md -->
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
 MathJax.Hub.Config({
 tex2jax: {
 inlineMath: [['$', '$'] ],
 displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
 }
 });
</script>

# 記事要約 『クラスタリング手法のクラスタリング』

- 20170707
- 20210718参照
- https://qiita.com/suecharo/items/20bad5f0bb2079257568

<!-- -------------------- -->

## クラスタリングとは
- 教師あり
- 内的結合
    - 同クラスタは類似
- 外的分離 
    - 異クラスタは類似しない

<!-- -------------------- -->

## クラスタリングの注意点
- 必ず主観が入る
    - 知見を得るため
    - 客観的な証拠とはならない
- 目的に応じた検証が必要
    - あくまで一つの視点から見た結果
- 分類後に分析、考察

<!-- -------------------- -->

## クラスタリングの分類
- 階層的 (hierarchical)
    - 類似するものからまとめる
	- 凝集型 (agglomerative)
		- 単リンク法 (single linkage method) 別名：最短距離法
		- 完全リンク法 (complete linkage method) 別名：最長距離法
		- 群平均法 (group average method)
		- Ward 法 (Ward's method) 別名：最小分散法
            - 代表的な手法
            - 最も明確なクラスターが出やすい
            - 外れ値に弱い
                - 主張は孤立していて良いのでは
		- セントロイド法 (centroid method) 別名：重心法
		- 重み付き平均法 (weighted average method)
		- メジアン法 (median method)
	- 分割型 (divisible)
		- **データ集合全体が一つのクラスタの状態から，順次クラスタを分割して，クラスタの階層を生成する．**
- 非階層的 (non-hierarchical) 別名：分割最適化 (partitional optimization)
	- K-means 法 別名：K 平均法
		- 派生的手法：K-means++
	- その他沢山

<!-- -------------------- -->

## それぞれの距離の定義
- euclidean：ユークリッド距離
- minkowski：ミンコフスキー距離
- cityblock：マンハッタン距離
- seuclidean：標準化されたユークリッド距離
- sqeuclidean：乗ユークリッド距離
- cosine：コサイン距離 (1からベクトルの余弦を引いたもの)
- correlation：層間距離(1から標本相関を引いたもの)
- hamming：異なる座標の比率を示すハミング距離
- jaccard：1からジャカード係数を引いた値
- chebychev：チェビシェフ距離(最大座標差)
- canbella：キャンベラ距離
- braycurtis：ブレイ・カーティス距離
- mahalanobis：マハラノビス距離
- 大方ユークリッドでよい？？
    - テキストはコサイン類似度やろ
    - 変化球を加えると比較評価がされにくいから？

<!-- -------------------- -->

## どの手法を使うか
- クラスタリング対象がサンプルか変数か
- 階層が必要なら階層的
    - Wardか群平均
    - eucidian, cosine, correlation, chebychev, mahalanobis
    - まず総当たりしてみる
- データが大きいなら非階層
    - k-means++法
