<!-- tex script for md -->
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
 MathJax.Hub.Config({
 tex2jax: {
 inlineMath: [['$', '$'] ],
 displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
 }
 });
</script>

# 論文調査記録 2021年04月26日
AL18036 片岡 凪

## 論文1. 逆強化学習を用いた転移可能な報酬関数の推定
- 著者
    - 勇樹北里
    - 幸代荒井
    - 千葉大学大学院工学研究科都市環境システムコース
- 掲載論文誌等
    - 人工知能学会全国大会論文集, vol. JSAI2016, p. 3D3OS30a2-3D3OS30a2, 2016, doi: 10.11517/pjsai.JSAI2016.0_3D3OS30a2.

### 1.どんなもの？
**転移学習と逆強化学習を組み合わせ、より学習効率の高い報酬関数を推定するシステム。通常の転移学習では元タスクから方策を転移させるが，今回提案した手法では報酬関数を転移させる。**
  
cf.  
- 転移学習
    - 解決が容易なタスクを難しいタスク用に転移
- 逆強化学習
    - エージェント（エキスパート）の行動軌跡と状態遷移確率から報酬関数を推定
    <!-- - 方策ではなく報酬を転移？
        - 方策＝下図の「最適な行動」
        - 逆強化学習⊂転移学習ではないのでは？
        - ~~転移~~ 学習？ -->
  
![](img/逆強化学習を理解する.webp)  
図1 Qiita(2017)「逆強化学習を理解する」より引用

### 2.先行研究と比べてどこがすごい？
**逆強化学習は、元とするエキスパートの行動より高い性能を得ることができない。本研究では、複数のエキスパートとそれを利用した複数の逆強化学習を行い、得た報酬を転移学習することによって、エキスパートの行動より高い性能を目指す。**

### 3.技術や手法のキモはどこ？
1. **強化学習で元タスクを用意**
    - スタート、ゴール、障害物の座標
    - 各迷路の最適方策を求める
    - 最適方策からエキスパートの行動軌跡を求める
2. **Abbeelの逆強化学習による各状態の報酬関数の推定**
3. **NNによる目標タスクへの報酬の転移**
    - 入力は元タスクの環境情報
    - 出力は求めた報酬関数
    - バックプロパゲーション
    - 目標タスクを入力して報酬関数を推定

### 4.どうやって有効だと検証した？
![](img/実験環境、学習曲線の比較.png)  

- **5*5マスの10個の迷路問題を1000回学習**
    - $5*5*10*1000*$(1マスの学習時間)
        - 1マスの学習時間はO(N)と仮定して10^6ループ程度？
        - これ以上は厳しそう
- 障害物はランダムに3-10個
    - ゴールに辿り着けないケースは除外
- 右回りの最短経路のみが学習できた
    - 何をもって学習できたといえるのか？
    - なぜ右回りのみ？
- 100試行の学習曲線の平均値を図示
- **差は出なかった**

### 5.議論はある？
- 差が出ない原因
    - **訓練数不足？**
    - **パラメータの調整不足？**
    - 提案手法の正確な評価
        - 可視化に近似曲線を使えば少しはわかりやすいかも？
    - **学習効率を改善する報酬関数ではなく、完全にエキスパートと一致するものを見つけてしまっているため？**


### 6.次に読むべき論文は？
- 木村研の昨年度の先輩が近い研究をしていた
    - 田植えの経路
- 失敗しない工夫のための技術
    - 転移学習のXAI
    - 逆強化学習のXAI

## 論文2. A Visual Analytics Framework for Explaining and Diagnosing Transfer Learning Processes
- タイトル和訳
    - 転移学習プロセスを説明・診断するためのビジュアル アナリティクス フレームワーク
- 著者
    - Y. Ma, A. Fan, J. He, A. R. NelakurthiとR. Maciejewski
- 掲載論文誌等
    - IEEE Transactions on Visualization and Computer Graphics, 2021, doi: 10.1109/TVCG.**2020**.3028888.

### 1.どんなもの？
- 深層学習モデルにおける伝達学習プロセスの解釈と診断をサポートするビジュアル分析フレームワーク
- データレベル、モデルレベル、フィーチャレベルで伝達されたノウハウを図示する一連の可視化デザイン

### 2.先行研究と比べてどこがすごい？
転移学習の分析を行うにあたり、先行研究では個々のモデルを分析するが、本研究では複数のモデル間の関係を明らかにできる。

### 3.技術や手法のキモはどこ？
- アルゴリズムの自動化
    - **応用するとより時間がかかる**
        - 抽出アルゴリズムを選択したレイヤーのサブセットで実行することで改善
- 視覚表現
    - **t-SNE投影とドメイン識別性プロットで視覚的な乱雑さが発生**
        - サンプリング法や集計法で不要な点を除去して改善
    - **重要なニューロンが多いと類似性行列が巨大に**
        - 各行列にフィルタをかけ、重要なニューロンを制限して改善
- タスクの汎用性
    - **データセットへのアクセスで同じプロトコルを共有**
        - 様々な深層伝達学習アプローチをサポート
        - 2つのドメインのモデルにおける層の帰属計算をサポート
        - 2つのモデル間でレイヤーのサブセットのみを共有する部分的な転送もサポート
        - 一般的なモデル選択のための1対1のモデル比較ツールとして、さらに一般化可能
- ターゲットオーディエンスと分析ガイドライン 
    - 性能評価ツール
    - 逐次的なモデル選択をさらにサポート
    - アルゴリズム設計
    - 手順
        - 希望するクラスを特定するために精度チャートとコンフュージョンテーブルを観察
        - インスタンスビューで2つのドメインからのデータ分布を検査
        - ニューロンの類似性と重要度ランキングの検査
            - ネットワーク関係ビューでクラスがアクティブになった後
            - ドメインの識別性と特徴のランキングの調査とともに考慮
    - ネットワーク関係ビューと特徴ビューで結果を探索
        - 2つのドメイン間で同じクラスの意味的な違いを理解

### 4.どうやって有効だと検証した？
ケーススタディとしてAlexNetにファインチューニング法を採用した画像分類タスクを行い、結果を2人のML専門家に評価させた。
  
cf. AlexNet
CNNベースのファストフォワードでない工夫されたNN

cf. ファインチューニング（事前学習）  
- 転移学習に似た言葉
- 既存のモデルで学習したネットワーク層のパラメータを新しいモデルに適用して初期化として新しいモデルに適用

### 5.議論はある？
- 今後の課題
    - モデルの類似性を明らかに
        - 異なるニューロンやウェイトの抽出基準を検討し、異なるニューロン帰属方法を評価
    - 複数のドメイン間の分析を促進
        - 複数のソースドメインの分析をサポート
        - 異なるソースドメインの転送性に関するより良い測定値を導入
    - 特定の応用分野におけるフレームワークの使い勝手を向上
        - 物体認識や医用画像処理など

### 6.次に読むべき論文は？

