<!-- tex script for md -->
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
 MathJax.Hub.Config({
 tex2jax: {
 inlineMath: [['$', '$'] ],
 displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
 }
 });
</script>

# 論文要約 『News Aggregation with Diverse Viewpoint Identification Using Neural Embeddings and Semantic Understanding Models』

- 20220110参照
- [1]M. Carlebach, R. Cheruvu, B. Walker, C. Ilharco MagalhaesとS. Jaume, 「News Aggregation with Diverse Viewpoint Identification Using Neural Embeddings and Semantic Understanding Models」, Proceedings of the 7th Workshop on Argument Mining, Online, 12月 2020, pp. 59–66. 参照: 1月 10, 2022. [Online]. Available at: https://aclanthology.org/2020.argmining-1.7


<!-- -------------------- -->

## 概要
- ニュースの量
-   反対意見から書かれた多くの出版物
    -   読者が多様で包括的な見解を得るのに困難
- 提案手法
    - 集約システム
        - 集約：複数の値の代表値，例えば総和，平均，最大などを求めること
            - https://www.kamishima.net/mlmpyja/nbayes2/distclass.html
        - トピックモデリング
        - セマンティッククラスタリング
        - 主張抽出
        - テキスト含意から構成される変換器
    - セマンティッククラスタ内の記事に示される視点を識別
        - 肯定、中立、否定含意
    - BERTベースの埋め込み
    - ベースラインのトピックモデリングアルゴリズムを11%の相対的向上
    - 最近の意味的類似性モデルの比較
    - ニュースデータに対する主張抽出のための変換器ベースのモデルの評価
    - 多様な視点識別のためのテキスト含意モデルの利用

<!-- -------------------- -->

## 図表
- 推論例を示すトランスフォーマーベースのシステム構成図
- 関連性予測の5つのステップ
- ホールドアウトしたMPQAデータを用いたF1において、XLNetが他モデルを上回る
- シャム BERT ベースのモデルは、STS-B と AFS で USE よりも 6%優れています。

<!-- -------------------- -->

## はじめに
- ニュースアグリゲーター
- 本システムでは
    - あらかじめ設定された基準や学習された動作ではない
        - ニュース記事で取り上げられた視点の一覧
        - どの視点を探索するかをユーザが決定できる
    - 構成
        - トピックモデリング
            - 複数のニュースソースから記事をクラスタ化
        - 仮説抽出
            - 各記事から意見を要約した文章（＝仮説）を抽出
        - 意味類似性
            - 異なる視点（＝意味類似性）を同定する
    - 仮説に基づき
        - 各トピック内の異なる視点（＝サブクラスタ）を特定
        - ある視点に関連する記事群から要約文（＝前提）を抽出
        - 各記事の仮説とそのサブクラスタの前提の間の含意を評価
            - テキスト固有性（Textual Entailment）によって
        - 仮説抽出と前提抽出をクレーム抽出のサブセットと定義
        - クレーム
            - ニュース記事に関連する視点を表現した文と定義
        - 仮説
            - 記事の視点を表す1つの要約文と定義
        - 仮説抽出と単一文書主観解析という用語を使い分ける
        - 前提
            - 複数の記事に共通する視点を表す1つの要約文
            - 前提抽出と複数文書主体性分析という用語を使い分ける

<!-- -------------------- -->

## 関連研究

### ニュースのアグリゲーション
- Thorneらは、事実抽出と検証のために、
- (RTE) を含むシステム
    - Document Retrieval, Sentence Selection, Recognizing Textual Entailment 
    - Thorn et al., 2018
    - 証拠となる文を選択
    - 入力として主張を想定
- 他の著者
    - 変換器ベースのモデルの性能を評価
        - 討論データに対するベースラインモデルに対し
        - （Chen et al., 2019a; Chen et al., 2019b; Gretz et al., 2020; Ein-Dor et al., 2020）
        - ニュースデータへの応用もあるが、若干構造が異なっている
        - 一つのニュース記事
            - 複数のトピックに分類
            - 同じ記事内で複数の意見
        - 討論データ
            - あらかじめ定義された特定の1つのトピックに直接的に沿うことが多い
            - 別々の意見が含まれる
- 我々のシステム
    - インデックス付けと検索を行う議論検索エンジンとは異なる（Stab et al.） 
    - ダイナミックな受信ストリームと複数のニュースデータのソースに適応するため
    - ニュース集約と視点発見問題を自動化するために言語モデルの汎化能力を探求
    - 独自のラベル付き記事データセットを開発

### トピックモデリング
- Multino-mial Latent Dirichlet Allocation (LDA) (Blei et al., 2003)
    - テキストコンテンツに基づいて文書をクラスタリングする一般的なアプローチ
    - Word2vecの埋め込みで単語を表現し、意味の一貫性を向上させる多くの代替案
        - （Mikolov et al.，2013a）
        - Embedded Topic Model (ETM) (Dieng et al., 2020)
            - 各文書を潜在トピックとして一意に表現
            - 各トピックは単語の意味空間への埋め込み
            - 本研究で利用
            - word2vec 埋め込みの代わりにtransformer-based 埋め込み
                - クラスタリングの品質を向上させるため
### 意味的類似性
- 意味的テキスト類似度（STS）
    - 2つの入力の意味がどの程度重なるかを捉える
    - 2つのテキスト本文の類似度を定量化
    - （Cer et al.、2017）
    - 最先端
        - 単語埋め込みアプローチに大きく依存
            - （Mikolov et al.、2013b）
            - 意味文脈を完全に捕捉する機能を欠く
        - InferSentなど
            - 複数の単語、フレーズ、またはセンテンスを単一の表現に埋め込む
            - （Conneau et al.）
    - 改善
        - Universal Sentence Encoder (USE) モデル (Cer et al., 2018)
        - BERT (Devlin et al., 2019) 
        - RoBERTa (Liu et al., 2019) 
        - GPT-3 (Brown et al., 2020)

### クレーム抽出
- 論文からの意見指向の情報抽出の重要な要素
    - 論文に関連する視点を表現する文（複数可）の特定
    - 単一文書の主観性分析
        - （Wilsonら、2005b; Chenら、2019b）
        - 初期の試み
        - 主観的表現の特定と同様のタスクのため
        - ルールベースの分類器
            - 以下で学習
                - Na¨ıve Bayes分類器
                - AdaBoost
                - 多角的質問応答（MPQA）意見コーパス（Wilsonら、2005b）
        - （Wilsonら、2005a; Somasundaran and Wiebe、2010）
    - 最近の研究
        - （Xu et al., 2019; Hoang et al., 2019; Han and Kando, 2019）
        - センチメント分析および意見マイニング
            - 微調整されたBERTモデル
            - およびBERTベースのモデル（Cer et al., 2018）
        - BERT
            - 質問と回答タスクのための複数の通路/文書に適用
                - （Wang et al.、2019）
                - しかし、複数文書の主観性分析-sisに適用された変換器ベースのモデルはほとんどない
                    - （Liu and Lapata, 2019）
    - 本研究
        - 仮説抽出を文分類タスクとして実装
        - Na¨ıve Bayes分類器に対してBERTベースのモデルを検討
        - 仮説抽出に対して変換器ベースのモデルが良好に機能するかどうかを判断
        - 前提抽出に抽象的な要約モデル
            - BART (Lewis et al., 2019)
            - T5 (Raffel et al., 2019) 

### テキストエンテイルメント
- Recognizing textual entailment (RTE) 
    - 前提文と仮説文が語彙的に一致しているかどうかにかかわらず
    - 仮説文が前提文を支持しているか、矛盾しているか、あるいは無関心であるかを識別
    -  (Sammons et al., 2012)
    -  テキスト・エンテイジメントの活用
        -  視点を支持する証拠の段落を見つける
            -  （Chen et al., 2019b）
    -  RTEに向けた試み
        -  Named Entity Recognition (NER) (Sammons et al., 2012)
        -  単語埋め込みを用いたLSTM
        -  BARTやRoBERTaなどの変換器ベースのモデル

<!-- -------------------- -->

## 方法
- デモ
    - https://harvard-almit.github.io/newsaggregator/
        - 様々なニュースメディアからスクレイピングされた1,000以上の記事からなるデータセットでテスト
            - Yahoo News
            - The Post and Courier
        - 図2
            - 処理の様子
            - トピックモデリング
            -   記事のクラスタIDを生成
            - 仮説抽出
                - クラスタ化された記事の仮説を生成
            - 意味類似性    仮説を用いてサブクラスタIDを生成し
            - 前提抽出
                - サブクラスタ内の記事の前提を生成
                - 仮説抽出と前提抽出の出力を消費
            - 関連性予測
                - ニュース集計システムの結果を提供
- トピックモデリング
    - 20 Newsgroupsデータ(Lang, 1995)と
    - Ad-justed Rand Index Scoring (Hubert and Arabie, 1985)
    - 3つのアプローチ
        - (i) gensim パッケージを用いた Latent Dirichlet Allocation (LDA)
            - ( ˇRehu°ˇrek and Sojka, 2011)
        - (ii) word2vec 埋め込みによる ETM
        - (iii) BERT ベース埋め込みのセントロイドによる ETM
            - (Blei et al.2003; Mikolov et al.2003), 2013a; Dieng et al.，2020）
        - ETMが使用する埋め込み数
            - num bert centroidsの値を選択
            - FAISSパッケージ（Johnson et al., 2019）
            - k-means clustering（k=num bert centroids）
            - クラスタリングされた記事に対する仮説抽出モデルの学習
                - MPQA Opinion Corpus v3.0の修正版
                    - （Deng and Wiebe, 2015）
                    - 表現力豊かな主観的要素
                - 文レベルの主観分析（文の二値意見分類）
                    - 前処理されたMPQAデータに対し
                    - 多項Na¨ıve Bayes分類器を学習
                    - BERT、XLNet (Yang et al., 2019) 、ALBERT（Lanら、2020）モデルを細かく調整
                        - HuggingFaceの変換ライブラリ（Wolfら、2020）
- 意味的類似性モジュール
    - トピック内の文書の生成された仮説を、意味的に関連する記事のクラスタに分類
    - 各記事は単一の、より具体的なトピックと関連づけられる
    - ピアソン相関係数を用いたUSEに加え
        - シャムネットワークstrc-ture（Reimers and Gurevych, 2019）における
            - BERT
            - RoBERTa
            - DistilBERT（Sanhら, 2019）を考慮
    - モデルの微調整
        - Argument Facet Similarity Corpus
            - (Misra et al., 2016)
        - STS-Benchmark dataset
            - SentEval (Conneau and Kiela, 2018) パッケージが提供
    - 前提抽出
        - IBMのProject Debater Claim Stance Dataset (Bar-Haim et al., 2017)
            - 微調整のための要約データセットに再フォーマットしようかと考えたが
                - 仮説抽出モジュールがすでにこの目的を達成している
                - データセットで提供される主張を利用しないせず
                - トピックを使用
                    - 記事のグループを表す文
        - transformers libraryで微調整
            - 大規模BARTモデル（406Mパラメータ）（Lewis et al., 2019）と
            - 小規模T5モデル（60Mパラメータ）（Raffel et al., 2019）の微調整
- システムの最終的な出力
    - テキスト含意モジュールによって提供
    - 意味的類似性サブクラスタ内の各記事について
    - 主張抽出モジュールから生成された前提および仮説が
    - テキスト含意モジュールに入力され
    - 仮説が前提に矛盾するか、含意するか、または無関係であるかを予測
- MNLI用に微調整されたFairseqの事前学習済みのRoBERTaとBARTモデル（Ott et al., 2019）の評価
    - BARTがMNLIタスクでRoBERTaと同様のパフォーマンスを示すため、
    - クレームスタンスデータセットのテキスト内包のためのトランスフォーマライブラリを使用
        - （Bar-Haim et al., 2017）により提示された

### 結果
- トピックモデリングの結果
    - word2vec埋め込みを用いたETM
        - 未見データでLDAを32%上回る
    - BERTベースの埋め込みを用いたETM
        - BERTセントロイド数
        - word2vecを用いたETMを11%上回る
        - 長鎖の文脈を考慮した埋め込みは有効
        - 未閲覧のデータに対する予測では
            - あるセントロイド数を超えるとオーバーフィッティング
            - BERTエンベッディングで学習したETMの改善が継続しない
        - 見たことのあるデータに対する予測では
            - BERTのセントロイド数（クラスタ数？）が100万個になると
            - ETMはword2vec embeddingsを用いたETMより17%性能が向上
- 仮説抽出
    - MPQAデータのホールドアウトデータセット
    - XLNet
        - Na¨ve Bayes分類器のベースラインを23%上回る
        - F1スコアではBERTとALBERTを上回る
    - ALBERTは高いマシューズ相関係数スコア
    - BERTベースのモデル
        - 特定の記事に対して異なるエンティティから明確な仮説を抽出することが可能
- 意味的類似性タスク
    - 表２
    - シャムネットワークにおける BERT ベースのモデルがUSE を上回る
        - 我々のユースケースに適している
    - **埋め込みベクトル間のコサイン距離と、人間がラベル付けした類似度スコアのピアソン相関**
        - 意味的に類似した文の認識には高い相関（r ≈ 0.84）
        - 引数のファセットの認識には中程度の相関（r ≈ 0.75）
    - 小型のDistilBERT
        - 大型のものと同様の結果
- 前提抽出
    - 検証データセットにおいて
        - T5で1.260の損失
        - BARTで6.192の損失
    - T5モデルは通常3文を出力
        - 予測された前提の中に逃げの文が発生するのを防ぐため
        - 長い文を含むようにさらに処理
    - BARTの予測
        - 学習データ内のトピックに限定されている
    - T5
        - 記事の内容に直接関連
        - 予測例
            - 「この家はリベラルアーツ運動を推進するのに最適な場所だろう」
            - 「この研究では、人々がウイルスに対する免疫を持っていれば、温暖な気候がウイルスの拡散を抑えるだろうと考えている」
- テキスト内包
    - 主張スタンスデータセットでは
        - RoBERTa（65％）
        - BARTは若干高い精度（67％）
    - 我々のデータセットでは
        - RoBERTaはBARTと比較して高い確率で予測
- 結果を踏まえ
    - 仮説抽出にはXLNet
    - 意味類似性にはSBERT
    - 前提抽出にはT5
    - テキスト含意にはRoBERTA
- ETMはリソース消費が激しい
    - LDAで代用
- 以下の例
    - 本システムの生成した2つのグループ
    - 1
        - 前提
            - コロナウイルスが流行している間、人々を遠ざけること、すなわち「社会的距離」を置くことが、流行をコントロールするために不可欠であるというのが、医療専門家の一致した意見である。
        - 仮説
            - キャロル・ローゼンバーグ氏は、「これでは社会的に距離を置くしかない」と語った。
        - 予測される含意
            - 矛盾（Contradiction）
    - 2
        - 前提
            - 全国の銀行口座にもうすぐお金が入るということで、詐欺師が政府のお金を集めるために個人情報を提供しなければならないと偽って、詐欺電話が急増しています。
        - 仮説
            - リンクをクリックすると、公式サイトのような場所に移動し、小切手を処理するために必要な個人情報を入力するように指示される。
        - 予測される含意
            - 中立


<!-- -------------------- -->

## 考察
- 我々のデータセット
    - ETMによって生成されたトピックは首尾一貫している
        - LDAによるトピックモデリングと比較
    - BERTを用いたETM
        - word2vecを用いたETMに比べ優れている
            - BERTのセントロイドの数がword2vecのセントロイドの数より多い場合
        - 計算量は大幅に増加
        - 良い性能
            - モデルの作成と予測の両方が同じ完全なデータセットに基づく場合
- 仮説抽出
    - 主観性解析と言い換えられる
    - XLNETとALBERTが高い性能
    - 本研究の新規性
        - 生成された仮説を意味論的類似性モジュールの入力として採用
        - 現在の最新モデル
            - 意味的類似性をペアワイズ回帰問題として扱う
            - ニュース集計のためのクラスタリングには計算効率が悪い
        - 変換器ベースのモデルがクラスタリングの品質を向上させることを見出した
            - USEと比較して
            - 特定のトピックに関する多様な記事群をユーザに提示するため
            - 意味的クラスタを効率的に発見できる
                - 標準クラスタリング手法
                    - k-Means++ (Arthur and Vassilvitskii, 2007) など
                - 密度ベースクラスタリング
                    - DBSCAN (Ester et al., 1996) など
        - 前提抽出が抽象的要約のタスクと密接に関係している
            - 記事群が発言に同意するかしないかを可能にするために前提を構築する必要があるから
        - 小型のT5モデルが大型のBARTモデルを著しく凌駕する
        - 複数文書および単一文書のクレーム抽出が、テキスト含意モジュールの入力となる情報量の多い前提および仮説になり得ることを実証
            - モデルが検出しない小さな矛盾がある
                - セクション4の2番目の前提-仮説のペア
            - 潜在的に予測できる
                - 別の前提-仮説のペアが選択された場合、
                - または仮説のフレーズを使用して予測が検証された場合
                - モデルは「個人情報を求める公式サイトのように見えるもの」というフレーズに予測に基づいていた
                - 記事中の前提-仮説のペアが異なると、同じ記事でも含意関係モジュールの予測が異なる
                    - 記事中の対立する視点や文中の異なる語句による

<!-- -------------------- -->

## おわりに
- 6 結論
- 読者が多様な視点から記事を閲覧できるニュースアグリゲーションシステム
- Embedded Topic Modelingによるベースラインモデルに対する相対的な改善率は10〜23%
- シャムネットワーク構造で細かく調整したBERTモデルによる意味的類似性が可能
- 文レベルの主観解析のために事前に学習した大規模言語モデルによる仮説抽出が可能
- 小規模なT5モデルを用いた場合、損失が5倍減少
- 事前に学習したBERTベースの文章含意モデルを用いて、多様な視点を特定できることを実証


<!-- -------------------- -->

## 片岡所感
- 自分の研究の上位互換。。。？
    - 語の定義をしていない
    - 要約している
        - 結合した文を使って類似度を出しているわけではない？

<!-- -------------------- -->

## 重要ピックアップ
- 埋め込み
    - num bert centroids
    - S-BERTではない
- クラスタリング
    - k-means
        - （k=num bert centroids）
- トピックモデリングの主観性分析のデータ
    - MPQA Opinion Corpus v3.0
- 意味的類似性のためのデータ
    - IBMのProject Debater Claim Stance Dataset (Bar-Haim et al., 2017)
        - 自分と同じ
        - 主張でなくトピックを使用
        - T5の方がいいらしい
- IBMで過学習している
    - 自分と同じ
    - BERTのセントロイド数が多いとなるらしい
- 評価
    - コサイン類似度と手動ラベルとの相関
- BERTがword2vecより計算コストが高い
    - 本研究と同じ
- 仮説（要約）を用いてクラスタリングを高速化
    - ニュースに適用できるように