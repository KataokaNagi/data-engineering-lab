<!-- tex script for md -->
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
 MathJax.Hub.Config({
 tex2jax: {
 inlineMath: [['$', '$'] ],
 displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
 }
 });
</script>

# 論文要約 『Scalable Fact-checking with Human-in-the-Loop』

- 20220110参照
- [1]J. Yang, D. Vega-Oliveros, T. SeibtとA. Rocha, 「Scalable Fact-checking with Human-in-the-Loop」, 2021 IEEE International Workshop on Information Forensics and Security (WIFS), Montpellier, France, 12月 2021, pp. 1–6. doi: 10.1109/WIFS53200.2021.9648388.

<!-- -------------------- -->

## 概要
- 情報が多い
    - 重複が多い
    - 事実を見落としがち
- 提案手法
    - 類似したメッセージをグループ化し、集約された主張にまとめる
    - 事実確認を加速
- 具体
    - ソーシャルメディアの投稿（例：ツイート）の集合をクリーニング
    - セマンティクスに基づいて全ての投稿のグラフを構築
    - 主張の要約
        - メッセージをグループ化
        - 2つのクラスタリング
    - 要約の評価
        - ROUGEスコア
            - 定量的な評価
        - 人間による定性的な評価
    - 要約間に有意な重複がないことを確認
        - 要約のグラフを作成
    - 28,818のオリジナルメッセージを700の要約クレームに削減
    - 代表的なクレームを整理・選択

<!-- -------------------- -->

## 図表
- 教師なしソーシャルメディア投稿要約パイプライン
    - セマンティッククラスタリング
        - 投稿をクラスタにグループ分
        - 各クラスタ内の投稿の数に基づいてランク付け
            - 頻度ベース
    - 要約／クレーム生成
        - 各クラスタのメッセージを要約し、情報量の多い要約を生成
- 異なるエムベッド法のクラスタリング結果比較
- 類似度の閾値δを変化させたクラスタリング結果
- 様々な要約方法を比較した要約性能
- BARTで生成された要約のグラフから得られたコミュニティ
- 1クラスタ内のツイートに対する4つの要約結果の例
- サマリーのグラフのコミュニティにおける全BARTサマリーの例

<!-- -------------------- -->

## はじめに
- 誤報が世間を騒がせるようになり、ニュースのファクトチェック機関も急増している。しかし、前者の生成・拡散速度は後者よりはるかに速い。このような誤報に対抗するため、事実確認の自動化ソリューションが多数提案されている。自動的な事実確認のための典型的なパイプラインは，通常，主張の確認価値の検出，証拠の検索，証拠の選択，真実性の検証という4つのステップからなる[1], [2]．いくつかの研究は、パイプラインにさらなる味付けをする。1) 繰り返し作業を避けるために、チェック前に検証済みのクレームとマッチングさせる [3]; 2) 検証後に説明を生成し、結果の信頼性を高める [4]．
自動的な事実検証は、文献上最も注目されている。しかし、人間のファクトチェッカーは、自動化されたソリューションからの結果を信用しないことが多い[5]。その理由は、自動化された方法は誤りを犯しやすく、誤った事実確認は事実確認組織の評判を著しく損なう可能性があるからです。むしろ、ファクトチェッカーが自動化手法に求めるのは、手作業によるファクトチェックのスピードを向上させることである。毎日、何十億ものメッセージがソーシャルメディアに投稿され、誤報が増え続けている今、ファクトチェックにはこれが不可欠なのである。これまで、ほとんどの研究者は、投稿がチェックする価値があるかどうかをチェックし[6]、クレームの数を減らすことでこの問題を処理しようとしてきました。しかし、ソーシャルメディアのメッセージはノイズが多いため、これでは十分でない可能性がある。また、チェックの価値があるかどうかの検出には、バイアスがかかりやすい手動ラベリングが必要である。
このことを念頭に置き、我々は教師なしという観点からこの問題にアプローチする。我々は、ソーシャルメディアからの投稿が

<!-- -------------------- -->

## 関連研究

### Check-worthness Detection
- 

### ソーシャルメディアメッセージの要約
- 

<!-- -------------------- -->

## タスクの定義
- 

### ショートメッセージアグリゲーション
- アグリゲーション
    - 一つの主張に関連する短いメッセージをグループ化
        - 主張に対して同じまたは反対の感情
        - 重複、ほぼ重複、言い換えの投稿
            - クラスタリングが教師なしであるため困難
                - 短いメッセージが1つのグループまたは別のグループに属するための境界を定義することは困難
- 最新の変換器ベースの言語モデル
    - 単語の意味を捉えることに長ける
- クラスタリングの入力
    - 文の意味を捉える必要がある
    - ショートメッセージの埋め込みにSentence-Transformers2 [12]
- 集計やクラスタリング
    - 標準的なクラスタリング手法
        - k-Means
        - 各ショートメッセージの埋め込みが少なくとも512次元
        - 時間がかかる
        - クラスタ数を事前に定義する必要がある
            - 我々の場合には適さない
    - 凝集型（階層型）クラスタリング（Agglomerative clustering）
        - クラスタ数を事前に設定する必要がない
        - 特徴点の非類似度に基づいてグループ化
        - 各点をクラスタとして出発
        - 非類似度が判定カットオフ値以下であれば，2つのクラスタを1つに統合
        - クラスタ数が未知
        - 決定カットオフを制御して、より小さいクラスタやより大きいクラスタを持つことができる
            - 有用
        - 手順
            - 初期の非類似度に対して、ショートメッセージの埋め込みの類似度行列Sを計算
            - 1-Sを非類似度行列として与える
            - 2クラスタ間の非類似度の計算方法を決めるリンク基準には
                - 2クラスタ内の任意の2点間の平均非類似度
    - ライデンコミュニティ検出（Leiden community de-tection）
        - グラフベース
        - グラフ内の最適なコミュニティ分割を見つける
        - ルーヴァンアルゴリズムの収束時間をより少ない計算量で改善
        - コミュニティのマイクロパターンに焦点
            - グラフのモジュール性を最大化する
        - グラフG(N, L)
            - 各ショートメッセージを表すノード集合N
            - ノード間の類似度合いを表すリンク集合L
        - ショートメッセージの埋め込みからグラフへの構築
            - ベクトル間の類似度行列を計算
                - -neighborhood法
    - 両手法
        - 全ポスト表現の類似度行列を計算
            - コサイン類似度
        - 類似度の判定カットオフ
            - 閾値をδ
            - =δを-graph construction parameter

### ショートメッセージ要約
- 

<!-- -------------------- -->

## 評価と分析
- 

### データセット
- 評価のデータセット
    - MM-COVID[18]
        - フェイクニュース検出用データセット
        - 各ニュース記事にツイート、リツイート、リプライといったソーシャルメディア上のコンテキスト
        - リツイート
            - ツイートの複製
        - リプライ
            - 主張自体との関連性が低い
            - 使用しない
                - ツイートの内容のみを利用
        - 選んだ理由
            - 各ニュースにはニュースの内容を要約したクレームがある
            - ラベルを評価に使える
            - ニュース要約は我々のショートメッセージ要約のグランドトゥルースとなる
        - テキスト分類の教師あり学習用のデータ
            - ラベルを評価に用いるのみ
            - 教師なし学習で利用
- コード
    - https://github.com/jingyng/scalable-fact-checking
- Twitter API4
    - 2,227のニュース記事に関連する92,070のツイートを収集
        - 収集時に約12%のツイートがTwitterから削除
        - 1,092件のニュース記事に関連する48,074件（52.2%）は英語
    - 英語のツイートのみを対象
    - 他の言語にも容易に適用できる
    - 前処理
        - 重複ツイート（同じIDのもの）
        - ユーザーによる言及
        - URL
        - ハッシュタグ
        - 絵文字を除去
- データセットの課題
    - ニュースの主張とツイート内容の間にミスマッチ
        - ニュースに関連するツイートがそのニュース内容とは関連性がない
            - 例
                - ニュースの主張
                    - コロナウイルスは5Gが原因
                - ツイートの内容：
                    - 最近、COVID-19による死亡に関連するCDCのデータを誤って解釈する人がいました
                - コロナウイルスはユタ州で400人以上、米国で177,000人以上の死者を出していることが分かっています
        - ニュースの主張とは関係のないツイート
        - ニュースクレームをツイートクラスターのゴールドサマリーとして使用する妨げ
            - ニュース主張との関連性が低いツイートを削除
                - 関連性判定カットオフθに基づく
                - このステップは要約を評価するためにのみ必要
                - 実際のケースでは実行する必要はない
- ツイートとそのニュース要約の関連性の計算
    - BERTscore[19]
        - cosine similarityよりも良い性能
        - デフォルトのモデル（roberta-large）
        - スコアを正規化
        - 計算した後、そのニュース概要と無関係なツイートをすべて削除
            - 閾値θ=0.1
        - フィルタリング
            - 4語以下のメッセージは意味のある情報を含んでいない
        - 959のニュース元記事に関連する28,818のツイートが残った

### クラスタリングの評価
- クラスタリング結果の評価
    - シルエット係数（Silhouette coefficient）6を使用
        - 真実のクラスタラベルがないため
        - -1～1の範囲
        - 値が高いほど、クラスタ間の重複が少ない
            - より明確に定義されたクラスタ
    - 埋め込みモデルとクラスタリング手法の2つの要素を考慮
- 埋め込みモデルの比較
    - 意味的に類似したメッセージを特徴表現空間内でより近くにマッピングする必要がある
    - 決定係数
        - δ=0.85
    - クラスタリング手法
        - ライデンコミュニティ検出
    - 全ての埋め込みモデルでそれなりの性能
        - cardiffnlp/twitter-roberta-baseを除く
            - 意外
            - ツイートで事前に訓練されているにもかかわらず
            - 大きなクラスタが1つしか得られなかった
        - 他のモデルは約700のクラスタ
            - ニュースの数である959より少ない
            - いくつかのニュースの主張が互いに類似
- クラスタリング手法の比較
    - 凝集型クラスタリング
    - ライデンコミュニティ検出
    - ニュースごとにクラスタリングしたもの（各ニュースが1つの投稿クラスタに対応する）も比較対象
    - 図2
        - 類似度閾値δを変化させてクラスタリング性能を比較
    - 埋め込みモデル
        - nli-roberta-base-v2
            - 最も性能が良かった
    - δが増加するとシルエット係数が増加
        - δが1に近い場合、重複に近いツイートだけをグループ化
            - ほぼ同じ結果
                - 類似した単語を含む投稿だけではない
                - 意味的に類似した投稿をクラスタリングしたい
                - クラスタリング結果の一部しか評価できない
- クラスタ内のニュースの分布
    - 1つのニュース主張に関連する投稿をクラスタリングしているかどうかを確認
        - 各クラスタ内のニュースを分析
        - 関連するニュースの主張が1つだけのクラスタの割合
            - agglomerativeが95.15%
            - Leidenが93.34%
            - 複数の関連するニュースを持つ1つのクラスタをランダムに調べた
                - agglomerative法
                - ニュースの主張が類似しているかどうかを確認
            - クラスタ内のニュースクレームの一例は以下の通り
                - ドナルド・トランプ米大統領またはジョー・バイデン大統領候補が、新型コロナウイルスの大流行について、"これまで一度も死んだことのない人々が死んでいる "時期であると言及した。
            - ドナルド・トランプはコロナウイルスについて、"今まで一度も死んだことのない人々が死んでいる "と発言した。
            - 現在進行中のCOVID-19のパンデミックについて、ドナルド・トランプ米大統領は、"People are dying today that have never died before. "と述べました。
                - 確かに1つの主張と関連
                - クラスター数（凝集型：804、ライデン：705）がニュース記事数（959）より少ない理由も説明

### 要約の評価
- 

<!-- -------------------- -->

## 結論
- 自動ファクトチェックソリューションは、実世界での展開にはまだ程遠いが
    - 人間のチェッカーを支援することが重要
        - スピードと包括的な検査を向上させるため
- 本論文
    - 2つのステップからなるパイプライン
    - 手動と自動のファクトチェックのギャップを埋める
    - 2つのクラスタリング手法
    - 4つの要約手法
    - 28,818のツイートから700の要約クレームまで、97%以上のオリジナルのソーシャルメディア投稿の数を大幅に削減
    - 事実確認プロセスのためにクラスタ化されたメッセージに関する知識を豊かにするより有益なクレームを提供できる
    - ヒューマンインザループを用いたより効率的かつ効果的なファクトチェックに向けた第一歩
- 課題
    - 1) クラスタリングのための信頼できる真正ラベルと要約評価のためのオラクル要約がない
    - 2) クラスタリング法は類似度行列全体を計算する必要がある
        - スケーラブルなファクトチェックのボトルネックになりうる
    - 3) 一部の要約はクレームではない
        - ファクトチェッカーにとって関心がない可能性がある
- 今後
    - より標準的なデータセットを構築し、評価
    - 数十万から数百万投稿の多様なデータセットに適用
    - クラスタリングと要約の効率の重要性を検討
    - 非主張を削除することで要約を洗練

### 
- 

### 
- 

### 
- 

<!-- -------------------- -->

## 片岡所感
- 頻度ベースは少数意見をつぶしてしまう
- 主張の選択が手動
    - データセットが頑張ってくれているもの
    - ニュースに対するSNSを利用
    - ニュースだけで判断できない
- 1つのニュース主張に関連する投稿のみをクラスタリング
    - 複数の主張に関連していてもいいじゃないか
    - agglomerativeが95.15%
    - Leidenが93.34%
- クラスター数が多すぎる
    - クラスター数（凝集型：804、ライデン：705）がニュース記事数（959）より少ない理由も説明
- 

<!-- -------------------- -->

## 重要ピックアップ
- 
