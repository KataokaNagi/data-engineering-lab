<!-- tex script for md -->
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
 MathJax.Hub.Config({
 tex2jax: {
 inlineMath: [['$', '$'] ],
 displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
 }
 });
</script>

# 週次報告書 2022年02月02日
AL18036 片岡 凪

## 1. 今回の報告会までに実施する予定だったこと
- 

## 2. 実施内容

### 目次
- 2.1 
- 2.2 
- 2.3 

### 2.1 

![](img/)
<div style="text-align: center;">
図. 
</div>
<br>
<br>

### 2.2 


### 2.3 


## 3. 次回までに実施予定であること
- 

## 4. メモ
- 本論執筆
    - 5000記事のクラスタリング
        - log 0120-131144
    - 関連研究の調査
        - BERTとクリック予測
            - [1]Q. Zhangほか, 「UNBERT: User-News Matching BERT for News Recommendation」, Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, Montreal, Canada, 8月 2021, pp. 3356–3362. doi: 10.24963/ijcai.2021/462.
            - ｓ
        - SBERT
            - [1]B. JuartoとA. S. Girsang, 「Neural Collaborative with Sentence BERT for News Recommender System」, JOIV : International Journal on Informatics Visualization, vol. 5, no. 4, Art. no. 4, 12月 2021, doi: 10.30630/joiv.5.4.678.
            - 12月で後付け臭い
        - BERTと旧システムとの比較
            - [1]C. Wu, F. Wu, T. QiとY. Huang, 「Empowering News Recommendation with Pre-trained Language Models」, arXiv:2104.07413 [cs], 4月 2021, 参照: 2022年1月28日. [Online]. Available at: http://arxiv.org/abs/2104.07413
            - アーカイブなので微妙
- スライド作成

