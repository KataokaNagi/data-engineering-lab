# scikit-learn、Keras、TensorFlowによる実践機械学習 第2版 第1章 読書メモ

- 片岡輪読担当分
    - 1.1-1.4 2021/03/17
    - 10前半  2021/04/07
    - 13前半  2021/04/28
    - 16前半  2021/05/26

## はじめに
- アプローチ
    - scikit-learn
        - 多くの効率的なアルゴリズム
    - TensorFlow
        - GPUによる分散NNエンジン
        - Google
    - Keras
        - NNの単純化API
        - TensorFlowなどと利用
- 必要な予備知識
    - Python
        - Numpy
        - Pandas
        - Matplotlib
    - 数学
        - 解析学
        - 線形代数
        - 確率論
        - 統計学
- おすすめ教材
    - Pythonチュートリアル
        - [LearnPython](https://www.learnpython.org/)
        - [python.org](https://docs.python.org/3/tutorial/)
    - 機械学習
        - [Cousera - Andrew Ng 機械学習講座](https://www.coursera.org/learn/machine-learning)
            - 数か月かかる
        - [scikit-learn ユーザーガイド](https://scikit-learn.org/skdoc)
        - [Dataquest](https://www.dataquest.io/)
            - 対話的教材
        - [Quora](https://jp.quora.com/search?q=Machine%20Learning)
            -  Q&Aサイト
        - [deeplearning.net](https://sites.google.com/site/minggaoshomepage/links/dee)
- 配布コード
    - Jyoyterノートブック
    - https://github.com/ageron/handson-ml2

## I 機械学習の基礎

### 1 機械学習の現状
- MLの対象や意味範囲
- MLの例
    - スパムフィルタ
    - OCR
    - 商品提案
    - 音声検索

#### 1.1 機械学習とは何か
- コンピュータがデータから学習するための科学技術
    - 学習：タスクの測定指標が向上する経験を得ること
- 語義
    - 訓練セット
        - 学習用のデータ例
    - 訓練インスタンス，標本
        - 個々のデータ例
    - 訓練データ    
        - 経験
    - 正解率
        - 性能指標

#### 1.2 なぜ機械学習を使うのか
- MLの手順
    1. 一般的な特徴を分析
    2. 特徴をもとに検出アルゴリズムを作成
    3. プログラムをテストし、実用レベルになるまで上を繰り返す
- MLの利点
    - データごとのアルゴリズムが不要
    - 複雑な問題の解決
    - 既知のアルゴリズムがない問題の解決
    - データマイニング
        - 特徴の予想外な相関関係，トレンドの発見
            - 高速に

#### 1.3 応用の例
- 製品の自動分類
    - イメージ分類
        - CNN（Convolutional：畳み込み）などを利用
- 脳腫瘍の検出
    - セマンティックセグメンテーション
        - CNNなど
- 記事の自動分類
    - テキスト分類 ∈ NLP（自然言語処理）
        - RNN（Recurrent：再帰型）
        - CNN
        - Transformer
- 不適切発言へのフラグ付加
    - テキスト分類
- 自動要約
    - テキスト自動要約 ∈ NLP
- チャットボット、パーソナルアシスタント
    - NLU（自然言語理解）
    - Q&Aモジュール
- 次年度収益の予測
    - 回帰タスク（値の予測）
        - 線形回帰
        - 多項式回帰モデル
        - SVM回帰
        - ランダムフォレスト回帰
        - 人工NN
    - 過去の業績指標の利用
        - RNN
        - CNN
        - Transformer
- 音声コマンド
    - オーディオサンプルの処理
        - 長くて複雑
            - RNN
            - CNN
            - Transformer
- クレカ詐欺の検知
    - 異常検知
- 購入履歴による顧客分類、販売戦略
    - クラスタリング
- 高次元データセットの図示
    - データの可視化
    - 次元削除
- 購入履歴から商品提案
    - 推薦システム
        - 人工NNなど
- ゲームのインテリジェントボット
    - アクションの選択
        - RL（Reinforced L：強化学習）
            - 全時間の報酬の最大化
            - AlphaGo
- Appendix：画像系 by 加瀬先輩
    - CNNs：
        - Convolutional Neural Networks、種類）AlexNet、VGG16、ResNet、GoogLeNet
    - Feature：
        - 特徴、CNNの抽出層で返還されたデータのことや、画像に内在するパターンのこと 類）Feature map
    - Image Classification：
        - 画像分類タスク.
    - Image Recognition：
        - 画像認識タスク、Detectionと似ているかも？どの範囲に物体が存在するか検知
    - Image Generation：
        - 画像生成、類）GAN
    - Image Segmentation：
        - 画像分割、あるルールに則ってパーツごとに分割するタスク
    - MNIST：
        - 0~9の手書きの数字（白黒）データセット
    - CIFAR10：
        - 一般物体認識用のデータセット、飛行機・船・自動車・トラック・猫・犬・蛙・馬・鳥・鹿の10クラス
    - ImageNet：
        - 画像分類で評価に使用されるデータセット
    - GAN：
        - Generative Adversarial Networks、画像を生成するモデル. BLEACH風(KBTIT）の顔変換等のpaperは面白い.
    - Adversarial Examples：
        - 敵対的サンプル、AIを騙す画像. 
    - XAI：
        - 説明可能AI、最近の流行り. モデルの予測根拠を可視化など. ex)SHAP、LIME、SmoothGrad、Guided-BackProp etc
    - Robustness：
        - 頑健性、研究フィールドの文脈で意味合いが異なるが、ノイズなどの影響を受けずに正しく分類する性質
    - Generalization：
        - 汎化、未知のデータに対しても正しく分類できる性質
    - Data Distribution：
        - データ分布（画像に限らず）、データセット1枚1枚で見た時に、青い鳥が多いとか、犬の背景は山が多いとか傾向
    - Label annotation：
        - 画像に付与された正解ラベルは本当に適切か？（複数写っている場合はどうする etc）という問題に対応する学問
    - Bouding Box：
        - 認識タスクで、物体が映り込んでいる領域のこと. 物体に合わせて適切に囲むことが目的

#### 1.4 機械学習システムのタイプ
- MLの分類
    - 人間の関与の有無
        - 教師あり
        - 教師なし
        - 半教師あり
        - 強化学習
    - その場で少しずつ学習可能か
        - オンライン
        - バッチ学習
    - 既知のデータポイントから予測モデルを構築するか
        - インスタンスベース学習
        - モデルベース学習
- 上記分類を組み合わせる

##### 1.4.1 教師あり／教師なし学習
- 教師あり学習
    - 訓練データに正解のラベル
    - 応用先
        - クラス分類
        - 回帰（regression）
            - 予測子(predictor)（＝一連の特徴量）からターゲットの数値を予測すること
            - 語源：背の高い両親の子供が平均に帰して背が低くなる傾向にあることを統計的に示した研究より
            - 出力が複数になる問題も
        - 回帰に分類が使えるものも
        - 分類に回帰が使えるものも
            - 例：ロジスティック回帰で分類確率を導出
    - 代表的なアルゴリズム
        - k近傍法
        - 線形回帰
        - ロジスティック回帰
        - SVM
        - 決定木，ランダムフォレスト
        - NN
- 教師なし学習
    - ラベルはない
    - 代表的なアルゴリズム
        - クラスタリング
            - 例
                - k平均法
                - DBSCAN
                - 階層的クラスタ分析（HCA：Hierarchial Clustering Analysis？）
                    - 分類の粒度が可変
        - 異常検知、新規性検知（anomaly detection, novelty detection）
            - 異常検知
                - 正常なインスタンスで訓練
                - 想定内の外れ値を検知
            - 新規性検知
                - ML以外のアルゴリズムで検知できない、分類済みだと思われるインスタンスで訓練
                - 予想外の外れ値を検知
            - 例
                - 1クラスSVM
                - アイソレーションフォレスト
        - 可視化、次元削減（visualization, dimension reduction）
            - 構造を保ちつつ、セマンティッククラスタを可視化
                - 片岡解釈：クラスタごとの座標などを保ちつつ、意味のある群の可視化用ラベル（次元）を増やす
                - 可視化例：クラスタ同士の重なり具合
            - 特徴量抽出（Feature Extraction）
                - 情報量を保ちつつ相関する複数の特徴をまとめ（次元圧縮）、データを見やすくする
                - 種々のMLの前処理に利用
                    - 速度向上
                    - 計算資源の節約
                    - 性能が向上することも
            - 例
                - PCA（Principal Component Analysis：主成分分析）
                - カーネルPCA
                - LLE（Locally-Linear Embedding：局所線形埋め込み法）
                - t-SNE（t-distributed Stochastic Neighbor Embedding：t分布確率的近傍埋め込み法）
        - 相関ルール学習（association rule learning）
            - 大量のデータの属性同士の興味深い関係を導く
                - 例：オムツとビール
            - 例
                - ア・プリオリ
                - Eclat
- 半教師あり学習（semisupervised learning）
    - 一部にラベル
    - ラベルの有無に応じた重みづけ？
    - 一部にラベリングして全体にラベリングすることも
    - 教師あり・なしの同時使用が多い
    - 例
        - DBN（deep brief network）
            - 教師なしのRBM（restricted Boltzmann machines：制限付きボルツマンマシン）
            - 教師ありで微調整
- 強化学習
    - 流れ
        1. エージェント（学習システム）が
        2. 環境を観察し
        3. 行動を選択して実行し
        4. 報酬 or ペナルティを得る。
        5. 報酬の高い方策（policy）を学習する。
        6. 学習した方策に従い、特別な行動を決定う
    - 例
        - ロボットの歩行
        - AlphaGo
            - 自分自身とも対局


##### 1.4.2 バッチ学習とオンライン学習
- バッチ学習（オフライン学習）
    - 事前に全ての訓練データで学習
    - オフラインで大量の時間と計算資源を割く
        - 流動的なデータには不向き
        - 分割して学習できないために計算資源に余裕が必要
- オンライン学習（差分学習 incremental L.）
    - ミニバッチで段階的に訓練
    - 使用済みデータの保持が不要
        - アウトオブコア（主記憶より大容量の学習システム）でも使用可能
            - 通常**オフ**ラインで使用
    - 学習速度（L. rate）が重要
        - 速いと古いデータを忘れる
        - 遅いと外れ値に強くなる
            - 実用上、速さは大事？
    - 性能が低下するデータの学習は打ち止める
        - 異常検知などを併用

##### 1.4.3 インスタンスベース学習とモデルベース学習
- 汎化（generalize）によるMLの分類
    - 新しいデータの予測のためのアプローチ
- インスタンスベース学習
    - 既存データの丸暗記
    - 新しいデータに類似度の尺度（measure of similarity）を適用
    - 例
        - k近傍法
- モデルベース学習
    - 線形関数、超平面などにモデリング
        - モデルパラメータΘ_i（慣例）による関数f(Θ_i)（モデル）を定義
            - モデルを評価する関数を定義
                - 良さを示す適応度関数g(f(Θ_i))？（utility f.）
                - 悪さを示すコスト関数h(f(Θ_i))？
            - Θ_iを変化させてg or hを大きくor小さくさせるよにに訓練（not 学習？）
    - 3種類の「モデル」に注意
        - 線形回帰などのモデル
        - 線形回帰などから構築したモデルアーキテクチャ
        - 訓練済みのモデル
    - [線形モデルでGDPと暮らし満足度の予測を行うコード](https://github.com/ageron/handson-ml2/blob/master/01_the_machine_learning_landscape.ipynb)
        - モデルベースもインスタンスベースも近い値を取る
        - 必要操作
            - データの検討
            - モデルの選択
            - コスト関数による訓練
            - 新しいデータで推論（inference）
```
# Code example
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import sklearn.linear_model
# import sklearn.neighbors

# Load the data
oecd_bli = pd.read_csv(datapath + "oecd_bli_2015.csv", thousands=',')
gdp_per_capita = pd.read_csv(datapath + "gdp_per_capita.csv",thousands=',',delimiter='\t',
                             encoding='latin1', na_values="n/a")

# Prepare the data
country_stats = prepare_country_stats(oecd_bli, gdp_per_capita)
X = np.c_[country_stats["GDP per capita"]]
y = np.c_[country_stats["Life satisfaction"]]

# Visualize the data
country_stats.plot(kind='scatter', x="GDP per capita", y='Life satisfaction')
plt.show()

# Select a linear model
model = sklearn.linear_model.LinearRegression()
# model = sklearn.neighbors.KNeighborsRegressor(n_neighbors=3)


# Train the model
model.fit(X, y)

# Make a prediction for Cyprus
X_new = [[22587]]  # Cyprus' GDP per capita
print(model.predict(X_new)) # outputs [[ 5.96242338]]
```
<!-- ここまで片岡の担当（後の演習問題も含む） -->

#### 1.5 機械学習が抱える難問
##### 1.5.1 訓練データ例の品質の低さ
- アルゴリズムとコーパスのどちらが優れているか

##### 1.5.2 現実を代表しているとは言えない訓練データ
- サンプリンズノイズによるサンプリンズバイアス

##### 1.5.3 品質の低いデータ
- 特徴量を持たないインスタンスへの対処
    - 属性を無視
    - インスタンスを無視
    - 欠損値を中央値などで補う
    - 持たないインスタンスだけでも学習

##### 1.5.4 無関係な特徴量
- 特徴量エンジニアリング
    - 特徴量選択
    - 特徴量抽出

##### 1.5.5 訓練データへの過学習
- 過学習
    - 正則化によって制限
        - ハイパーパラメータで調節
- 自由度
    - 変数の制限
        - 0にする
        - 変化を制限

##### 1.5.6 訓練データへの過少適合
- 過少適合
    - モデルが単純すぎ
    - 現実の問題は複雑で、表しきれるデータの選別は至難

##### 1.5.7 一歩下がって復習しよう

#### 1.6 テストと検証
- 訓練セットとテストセットで分ける
    - 8:2-7:3
    - データが多ければ1%でもよい
- 汎化誤差（標本外誤差）
    - 新しいデータでの誤り率
- 過学習
    - 訓練誤差<汎化誤差

##### 1.6.1 ハイパーパラメータの調整とモデルの選択
- モデルの選択
    - 両方の汎化性能を比較
    - 特定のハイパーパラメータに特化した学習にならぬように
        - ホールドアウト検証
            - 検証セット（開発セット）
            - 交差検証
                - 交差して平均化

##### 1.6.2 データのミスマッチ
- モデル
    - 観察を単純化
        - 汎化しない過剰な細部の除去
        - 前提が必要
            - 例：線形モデル
                - 線形
                - インスタンスと直線との距離はノイズ
            - **前提がないと比較評価はできない**
                - ノーフリーランチ定理
            - アプリオリ（無前提）
- ノーフリーランチ定理

#### 1.7 演習問題
- 片岡担当分（1.4）まで
    1. 機械学習の定義
        - 片岡の解答
            - コンピュータが、データからタスクの測定指標が向上する経験を得るための科学技術
        - テキストの解答
            - データから学習できるシステムをつくること
                - 学習：何らかの測定手段に基づき、あるタスクを処理した成績が上がる操作
    2. 機械学習が発揮する問題の4タイプ
        - 片岡の解答
            - データごとのアルゴリズム実装が大変な問題
            - 複雑な問題
            - 既知のアルゴリズムがない問題
            - 予想外な相関関係とトレンドを抽出する問題（データマイニング）
        - テキストの解答
            - アルゴリズムを使ったソリューションがない複雑な問題の解決
            - 思い付きの規則が延々と続くものに代わるモジュールの開発
            - 変動する環境に合わせて自分を修正できるシステムの開発
            - 人間の学習の支援（データマイニングなど）
    3. ラベル付き訓練セットとは
        - 片岡の解答
            - 人間による分類を行った全ての訓練データ
        - テキストの解答
            - 個々のインスタンスに問題の答えが含まれている訓練セット
    4. 教師あり学習の応用例2つ
        - 片岡の解答
            - 回帰
            - クラス分類
        - テキストの解答
            - 回帰
            - 分類
    5. 教師なし学習の応用例4つ
        - 片岡の解答
            - クラスタリング
            - 異常検知、新規性検知
            - 可視化、次元削減
            - 相関ルール学習
        - テキストの解答
            - 同上
    6. 未知の領域を探索する、ロボットで使えるMLは
        - 片岡の解答
            - 強化学習
        - テキストの解答
            - 強化学習
            - 教師あり・なし学習だと不自然になる
    7. 顧客を分類するMLは
        - 片岡の解答
            - クラスタリング（教師なし学習）
        - テキストの解答
            - 集団の定義が分からない場合
                - クラスタリング（教師なし学習）
            - 集団の定義が分かっている場合
                - 分類アルゴリズム（教師あり学習）
    8. スパム検出は教師ありorなしか
        - 片岡の解答
            - 教師あり
                - スパムの特徴は限られており、アルゴリズムを適用する必要がありそう
        - テキストの解答
            - 教師あり
                - ラベル（スパムorハム）を付けたメールでアルゴリズム訓練
    9. オンライン学習システムとは
        - 片岡の解答
            - ミニバッチで段階的に訓練する、計算資源の要求が比較的少ない学習
        - テキストの解答
            - バッチ学習システムと異なり、差分データで学習可能
            - データが変化するシステムや自律的なシステムに適用可能
            - 機敏に学習可能
            - 極端に大規模なデータを使用可能
    10. アウトオブコア学習とは
        - 片岡の解答
            - 主記憶より大容量のデータを扱う学習システム
        - テキストの解答
            - 同上
            - データをミニバッチに分割し、オンライン学習のテクニックを使って学習
    11. 類似度の尺度を用いる学習は
        - 片岡の解答
            - インスタンスベース学習
        - テキストの解答
            - 同上
            - 訓練データを丸暗記させた上で新しいインスタンスを与え、類似度の尺度から暗記したインスタンスに最も近いものを採択
    12. モデルのパラメータと学習アルゴリズムのハイパーパラメータの違い
        - 片岡の解答
            - モデル
                - 直線の傾きなど
            - アルゴリズム
                - モデルの組み合わせ方の調節値
        - テキストの解答
            - モデル
                - 同上
            - アルゴリズム
                - 汎化するように調節するパラメータ
                - 正則化の程度など
    13. モデルベースのMLは何を探すか。良い手法は何か。どう予測するか。
        - 片岡の解答
            - 汎化する指標を探す。汎化すれば良い指標。モデルとなる関数に入出力する。
        - テキストの解答
            - 汎化する最適なモデルパラメータを探す
            - コスト関数やモデルの複雑度に対するペナルティの付与
            - アルゴリズムが見つけたパラメータを用いた予測関数に新インスタンスの特徴を付与
    14. MLの難問4つ以上
        - 片岡の解答
            - 過学習
            - 過少適合
            - ハイパーパラメータの調整
            - データの用意
            - データの前処理
        - テキストの解答
            - データの欠落
            - データの品質の低さ
            - 全体を代表していないデータ
            - 関係のない特徴量
            - 訓練データに過少適合する単純なモデル
            - 訓練データに過学習した複雑なモデル
    15. 訓練データの結果＞新データの結果 のときは何が問題か。解決法３つ
        - 片岡の解答
            - 汎化が上手くいっていない。
            - 問14の内容を見直す
        - テキストの解答
            - 過学習
            - 対策
                - 訓練データを増やす
                - モデルの単純化
                    - アルゴリズムの単純化
                    - パラメータを減らす
                    - 特徴量を減らす
                    - モデルの正則化
                - 訓練データのノイズ低減
    16. テストセットとは何で、なぜ必要か
        - 片岡の解答
            - 汎化しているかを確認するデータ。
        - テキストの解答
            - 本番稼働前に新インスタンスの汎化誤差を推計するもの
    17. 検証セットの目的
        - 片岡の解答
            - ？
        - テキストの解答
            - モデルの比較
                - 最良のモデル選択
                - ハイパーパラメータの調整
    18. 訓練ー開発セットとは
        - 片岡の解答
            - ？
        - テキストの解答
            - 訓練データと検証・テストデータの間に不一致があるときに用いる
            - 訓練セットの一部
            - 過学習か不一致かが判明
    19. テストセットによるハイパーパラメータの調整が起こす問題は
        - 片岡の解答
            - ？
        - テキストの解答
            - テストセットの過学習
